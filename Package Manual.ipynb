{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MeTEA (Metagenomic Taxa Evaluation and Assessment) \n",
    "\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "Create a Misc object, then use the function *main()*.\n",
    "    \n",
    "Arguments:\n",
    "- <u>Input</u>: the name of the ground truth profile file\n",
    "- (optional) the name of the output excel file; <Default: **TaxaPerformanceMetrics_byTool**>\n",
    "- (optional) input directory of all profiles, including the ground truth; <Default: *Current Working Directory*>\n",
    "- (optional) the output directory; <Default: Current *Working Directory*>\n",
    "- (optional) **1** if you want individual .csv files of each tool's confusion matrix; <Default: **0**>\n",
    "- (optional) **1** if you want dendrograms of each confusion matrix and taxonomy level; <Default: **0**>\n",
    "\n",
    "<u>Output</u>: the excel file name, a .xlsx of six sheets: True Positives, False Negatives, False Positives, True Negatives, Precision, Recall of each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeTEA.precall import Misc\n",
    "Quick = Misc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT AND USE THIS VERSION!\n",
    "Quick.main(\"truth.profile\", \"Test_Tool\", \"MeTEA\\\\tests\", \"MeTEA\\\\tests_results\", csv=1, dendros=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Top Taxa\n",
    "\n",
    "Using the funciton *get_top_taxid()* will create a csv file of the top Taxa based on the difficulty the tools had in detecting it and one of the confusion matrix metrics.\n",
    "\n",
    "##### Arguments <*get_top_taxid()*>:\n",
    "- <u>Input</u>: The number of Tax IDs to include\n",
    "- (optional) The metric to evaluate by; <Default: **tp** (True Positives)>\n",
    "    - available metrics are:\n",
    "        - tp (true positive)\n",
    "        - tn (true negative)\n",
    "        - fp (false positive)\n",
    "        - fn (false negative)\n",
    "- (optional) The difficulty level; <Default: **least**>\n",
    "    - available dificulties:\n",
    "        - least\n",
    "        - most\n",
    "\n",
    "<u>Output</u>: the file name and path as well as a spreadsheet containing the Tax IDs. It's name is formatted like this: *'Top_Difficulty-METRIC_taxid.xlsx'*\n",
    "- Example: \"Top_Least-TP_taxid.xlsx\"\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "Using *create_heat_map()* will create a heatmap to visual the data for the tap Taxa.\n",
    "\n",
    "##### Arguments <*create_heat_map()*>:\n",
    "- <u>Input</u>: The name of the spreadsheet containing the list of Tax IDs. They should be formatted into a column labeled 'Tax ID'.\n",
    "\n",
    "The output is a heat map. It's name is formatted as the name of the input file with the extentsion replaced with *'_Heat_Map.png'*.\n",
    "</br>\n",
    "</br>\n",
    "<u>NOTE</u>: The values used in this graph are normalized to the values in the ground truth. For Example, if the ground truth detected a taxa in 9 out of the total number of samples, any tool that also detected the taxa in 9 samples will have a score of 1. Any tool that detected the taxa in less than 9 of the samples will have a score of less than 1. Vice verse for if the tool detected the taxa in more than 9 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_3_hard_tp = Quick.get_top_taxid(3, 'tp', 'least')\n",
    "Quick.create_heat_map('Top_Least-TP_taxid.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How they work\n",
    "\n",
    "The main purpose of this module is to calculate each Tax ID's confusion matrix and save that and other information into a .csv file.\n",
    "\n",
    "Each module does a specific step in that process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser\n",
    "\n",
    "Parse separates the relevant information for each Tax ID (ie. rank, abundance, etc.) into dictionaries. Both functions *parse_data()* and *main()* return a dictionary of dictionaries variable, but *main()* does a little more with it.\n",
    "\n",
    "The returned variable looks like this:\n",
    "\n",
    "    {Sample Number : dict}\n",
    "                   - {Rank : dict}\n",
    "                           - {Tax ID : Abundance}\n",
    "There is an alternative parsing format that can be used to get other information about the Tax ID (name and rank), which returns a dictionary of dictionaries variable that looks like this:\n",
    "\n",
    "    {Sample Number : dict}\n",
    "                  - {Tax ID : list}\n",
    "                            - [rank, name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeTEA.profile_parser import Parser\n",
    "\n",
    "myParser = Parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main(self, f, t=0)\n",
    "\n",
    "This function calls inner functions to create and return a dictionary where sample number is the key and a dictionary of {Rank : {Tax ID : Abundance}} is the value.\n",
    "    \n",
    "The variable t is optional and the default is zero. Passing one for t instead of zero tells the program to use the alternative parsing format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = myParser.main(\"pred.profile\")\n",
    "sample_2 = myParser.main(\"pred2.profile\")\n",
    "\n",
    "sample_1_alt = myParser.main(\"pred.profile\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print_samples(self, samples, t=0)\n",
    "\n",
    "This function prints the contents of the dictionary samples in a viewable way.\n",
    "\n",
    "The variable **t** defaults to zero, printing in the format of the default sample format. If **t=1**, it prints in the alternative format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~DEFAULT~\")\n",
    "myParser.print_samples(sample_1)\n",
    "print(\"~ALTERNATIVE~\")\n",
    "myParser.print_samples(sample_1_alt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparator\n",
    "\n",
    "Comparator compares two sample dictionaries to find the common Tax IDs in each sample and to combine the Tax IDs in each sample into a new dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeTEA.comparator import Comparator\n",
    "\n",
    "myComparer = Comparator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main(self, files, t=0)\n",
    "\n",
    "The *main()* function takes in a string (file names) of two profile names (with the '.profile' part) separated by a space. If the profile files are not in the same directory as the file running this code, add the directory to the file names. Make sure there are no spaces in the directory path.\n",
    "\n",
    "It also accepts an optional argument **t** that is used when the function calls on *Parser.main()*.\n",
    "    \n",
    "This function returns two dictionaries where sample number is the key and a set is the value. The sets for the two dictionaries contain all the Tax IDs from both samples, excluding repeats, and the Tax IDs both samples had in common, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_1_2, combined_1_2 = myComparer.main(\"tests\\\\truth.profile tests\\\\pred.profile\")\n",
    "print(common_1_2)\n",
    "print(combined_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save_tax_ID(self, samples)\n",
    "\n",
    "This function iterates over a samples dictionary to create and return a dictionary where sample number is the key and a set of Tax IDs from that sample is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tax_ID_1 = myComparer.save_tax_ID(sample_1)\n",
    "sample_tax_ID_2 = myComparer.save_tax_ID(sample_2)\n",
    "print(sample_tax_ID_1)\n",
    "print(sample_tax_ID_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common_tax_ID(self, tax_id1, tax_id_2)\n",
    "\n",
    "This function creates and returns a dictionary where sample number is the key and a set containing the common Tax IDs between two sample files is the value. It iterates over a samples dictionary to save each set under a sample number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dict_1_2 = myComparer.common_tax_ID(sample_tax_ID_2, sample_tax_ID_1)\n",
    "print(common_dict_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine_tax_ID(self, tax_id_1, tax_id_2)\n",
    "\n",
    "This function creates and returns a dictionary where sample number is the key and a set containing the Tax IDs from both sample dictionaries is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict_1_2 = myComparer.combine_tax_ID(sample_tax_ID_2, sample_tax_ID_1)\n",
    "print(combined_dict_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion\n",
    "\n",
    "Confusion uses both Comparator and Parser to create a confusion matrix for every Tax ID in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeTEA.confusion_matrix import Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\__init__(self, tru, fn)\n",
    "\n",
    "The constructor for Confusion objects is a little different since it takes two arguments, one for the name of the ground truth file and one for the name of the predicted file (including the '.profile' part).\n",
    "\n",
    "If the files are not in the same directory as the file running this code, add the directory path to the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confu = Confusion(\"tests\\\\truth.profile\", \"tests\\\\pred.profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_file_name(self) and get_truth(self)\n",
    "\n",
    "These functions return a string containing the name of the predicted and truth files respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Truth:\", Confu.get_truth(), '\\nPredicted:', Confu.get_file_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_file_name(self, tru) and set_truth(self, fn)\n",
    "\n",
    "These two functions allow you to change the ground truth or predicted file whenever you need to. It also makes it so that you only need one Confusion object for multiple predicted files or even multiple truth files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confu.set_file_name(\"tests\\\\pred2.profile\")\n",
    "Confu.set_truth(\"tests\\\\pred.profile\")\n",
    "print(\"Truth:\", Confu.get_truth(), '\\nPredicted:', Confu.get_file_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main(self, csv=\"yes\", t=0)\n",
    "\n",
    "This function uses *Comparer* and *Parser* and internal functions to create a confusion matrix for the predicted file, then save that data as a .csv file. The automatic name for that .csv file is the truth and predicted file names joined by two hyphens (ie. Truth = 'truth.profile', Predicted = 'pred.profile', .csv file name = 'truth--pred.csv').\n",
    "    \n",
    "It also returns the confusion matrix it created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p_matrix = Confu.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check_matrix_error(self, matrix)\n",
    "\n",
    "This a supplementary function that checks to make sure the sum of the numbers in the confusion matrix equal the total number of samples in the ground truth file for each Tax ID. It then returns a list of the Tax IDs with confusion matrices that are over and under that number respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confu.check_matrix_error(t_p_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "\n",
    "*Misc* is mainly for finding the confusion matrices of multiple profiles at once and creating an .xlsx file to display the confusion matrix values for each predicted file and the ground truth on separate sheets. It also uses the Precall class to calculate and add a sheet for precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeTEA.precall import Misc\n",
    "\n",
    "myMisc = Misc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_truth(self, truth)\n",
    "\n",
    "This function sets the file name of the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.set_truth(\"new_truth.profile\")\n",
    "print(myMisc.get_truth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_input_path(self, ip)\n",
    "\n",
    "This function sets the directory path for the input files (ground truth and predicted profile files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.set_input_path('new_input_path')\n",
    "print(myMisc.get_input_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_output_path(self, op)\n",
    "\n",
    "This function sets the directory path for the output files (i.e. the .xlsx file and dendrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.set_output_path('new_outputs')\n",
    "print(myMisc.get_output_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_output_name(self, on)\n",
    "\n",
    "This function sets the name of the .xlsx output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.set_output_name('A_Different_Name')\n",
    "print(myMisc.get_output_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main(self, gnd_truth, excel_name=\"TaxaPerformanceMetrics_byTool\", gen_dir='\"\", file_path=\"\",  csv=0, dendros=0)\n",
    "\n",
    "This function takes the name of the ground truth file, the name of the output .xlsx file, the directory of the profile files, the directory for the output file, and a string to  determine whether or not to also create .csv files for each tool's confusion matrix.\n",
    "- The name of the ground truth file is a string.\n",
    "- The name of the output .xlsx file can be anything you choose. The default is \"TaxaPerformanceMetrics_byTool\".\n",
    "- The directory of the profile files needs to include all the profiles being evaluated plus the ground truth file. They should all be in the CAMI format and have the extension '.profile'. The default is the current working directory.\n",
    "- The directory for the .xlsx output file can be anything you choose. The default is the current working directory.\n",
    "- The .csv files contain the confusion matrix for each Tax ID. One file would be made for each tool. If you want the progam to output them, pass in **1**, otherwise leave blank since the default is **0**. The directory for these files will be the same as the .xlsx output file's.\n",
    "- The dendrograms are .png files that show how similar each tools results are to each other using the bray-curtis distance. A graph is made for each taxanomic rank and metric (ie. Genus_TP, GENUS_FP, ..., GENUS_ALL, etc.). To create these, pass in **1**.\n",
    "        \n",
    "After saving the output excel file, dendrograms based on the bray curtis distance are created and saved as .png files. These are created for each taxa level for True Positives, False Negatives, False Positives, True Negatives, and Precall (the harmonic mean of Precision and Recall) to compare the tools to each other. There is also a dendrogram for each confusion matrix metric that includes all taxa levels and uses traceback to include the Tax IDs that weren't directly reported but were detected. The .png files are also saved in the same directory as the output excel file.\n",
    "\n",
    "The ground truth will be included in all the evalutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.main(\"truth.profile\", \"Test_Tool\", \"tests\", \"tests_results\", csv=0, dendros=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_top_taxid(self, x, metric=\"tp\", difficulty=\"least\")\n",
    "\n",
    "This function finds and creates a .xlsx file of the **x** number of taxa with the top difficulty passed based on the metric chosen. Only true taxa are included in this.\n",
    "\n",
    "<u>NOTE</u>: Before running this, the main() function should be run or these values should be set: the ground truth file name, output file directory, and output file name.*\n",
    "\n",
    "- The ground truth file name should be the same as the one used for the main() .xlsx output file.\n",
    "- The output file directory is the same as the one used for the main() .xlsx output file.\n",
    "- The output file name is the main() .xlsx output file name.\n",
    "    \n",
    "<u>x</u> is the number of Tax IDs to include\n",
    "    \n",
    "<u>metric</u> is the way the top taxa will be calculated. It can be **tp** (True Positives), **fn** (False Negatives), **fp** (False Positves), **tn** (True Negatives), or **precall** (the harmonic average of Precision and Recall). **tp** is the default.\n",
    "    \n",
    "<u>Difficulty</u> is what kind of Tax ID you're looking for. **most** or **least** can be passed to get the top easiest or hardest Tax IDs (Note: only the *precall* option really has 'nan' values). The default is **least**.\n",
    "    \n",
    "<u>NOTE</u>: *None of these arguments are case-sensitive.*\n",
    "    \n",
    "The top taxa will be saved into a .xlsx file in whichever output directory was last passed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.get_top_taxid(3, 'tp', 'least') # Gets the top three Taxa with the lowest True Positive scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_heat_map(self, file_name)\n",
    "\n",
    "This function creates a heat map with a dendrogram on top using a list of Tax IDs from the file passed.\n",
    "\n",
    "<u>NOTE</u>: Before running this, the main() function should be run or these values should be set: the ground truth file name, output file directory, and output file name. *get_top_taxid()* should also be run first.\n",
    "\n",
    "- The ground truth file name should be the same as the one used for the main() .xlsx output file.\n",
    "- The output file directory is the same as the one used for the main() .xlsx output file.\n",
    "- The output file name is the main() .xlsx output file name.\n",
    "    \n",
    "<u>file_name</u> is the name of the spreadsheet with the list of Tax IDs, which should be grouped into a column labeled 'Tax ID'.\n",
    "    \n",
    "After the heat map is created, it will be saved as a .png file iin whichever output directory was last passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMisc.create_heat_map('Top_Hard-TP_taxid.xlsx') # creates a heat map based on the list of Tax IDs previously calculated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
